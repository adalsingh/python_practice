{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This code extracts administrative data from the website of the Mahatma Gandhi National Rural Employment Guarantee Scheme, a large pay-for-work program administered by the Government of India. The code is updated as of August 8, 2014."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1. Define the sample that you want to extract data for.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Define sample\n",
      "#Can be expanded to include: other indicators, other states, other districts, other years\n",
      "url_head = 'http://164.100.128.68/netnrega/state_html/'\n",
      "\n",
      "state_id1 = 'BIHAR'\n",
      "state_id2 = '05'\n",
      "\n",
      "district_list = []\n",
      "district_list.append(['ARARIA', '0541'])\n",
      "district_list.append(['ARWAL', '0551'])\n",
      "\n",
      "year_list = ['2012-2013','2013-2014']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2. Import necessary Python packages. **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import packages\n",
      "import pandas as pd\n",
      "import requests\n",
      "from pattern import web\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3. Define a function to extract data from a single generalized table.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def workdelay_table_extract(url):\n",
      "    \"\"\"\n",
      "    Input: A URL to a GP-level table for one block on work delays\n",
      "    For example: 'http://164.100.112.66/netnrega/state_html/wrk_behind_sch.aspx?project=ALL&block_name=%E0%A4%95%E0%A5%81%E0%A4%AE%E0%A5%8D%E0%A4%B9%E0%A5%87%E0%A4%B0&district_name=BHARATPUR&district_code=2707&state_name=RAJASTHAN&state_code=27&block_code=2707006&fin_year=2009-2010&page=B'\n",
      "    Returns: A Pandas DataFrame of that data\n",
      "    \"\"\"\n",
      "    \n",
      "    # Get Web DOM\n",
      "    html_text = requests.get(url).text\n",
      "    dom = web.Element(html_text)\n",
      "    \n",
      "    # State, District, Block names\n",
      "    header_text = dom.by_tag('tr')[4].content\n",
      "    temp1 = re.split(\"\\n+\", header_text)\n",
      "    temp2 = re.split(\":?\", temp1[2])\n",
      "    state = re.sub(\"District\",\"\",temp2[1]).strip()\n",
      "    district = re.sub(\"Block\",\"\",temp2[2]).strip()\n",
      "    block = temp2[3].strip()\n",
      "    \n",
      "    # Extract data in table\n",
      "    gp = []\n",
      "    delay_1to30 = []\n",
      "    delay_30to60 = []\n",
      "    delay_60to90 = []\n",
      "    delay_more90 = []\n",
      "    delay_total = []\n",
      "    \n",
      "    for x in dom.by_tag('tr')[7:-1]:\n",
      "        gp_name = x.by_tag('td')[0].content\n",
      "        gp_name = gp_name.strip()\n",
      "        gp.append(gp_name)\n",
      "        delay_1to30.append(x.by_tag('td')[1].content)\n",
      "        delay_30to60.append(x.by_tag('td')[2].content)\n",
      "        delay_60to90.append(x.by_tag('td')[3].content)\n",
      "        delay_more90.append(x.by_tag('td')[4].content)\n",
      "        delay_total.append(x.by_tag('td')[5].content)\n",
      "    dictionary = {'gp': gp, 'delay_1to30': delay_1to30, 'delay_30to60': delay_1to30, 'delay_60to90': delay_60to90, 'delay_more90': delay_more90, 'delay_total': delay_total}\n",
      "    \n",
      "    # Create Pandas DataFrame\n",
      "    dictionary['state'] = [state]*len(gp)\n",
      "    dictionary['district'] = [district]*len(gp)\n",
      "    dictionary['block'] = [block]*len(gp)\n",
      "    df = pd.DataFrame(dictionary)\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**4. Define a function to obtain all block URLs for a single generalized district.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def workdelay_district_tables(url_start, state_name, state_num, district_name, district_num, finyears):\n",
      "    \"\"\"\n",
      "    Input: Location IDs\n",
      "    Returns: A Pandas DataFrame of all workdelay data in that district\n",
      "    \"\"\"\n",
      "    \n",
      "    #Get block URLS\n",
      "    url = url_start + \"wrk_behind_sch.aspx?project=ALL&page=D&state_name=%s&state_code=%s&district_name=%s&district_code=%s&fin_year=%s\" %(state_name,state_num,district_name,district_num,finyears)\n",
      "    html_text = requests.get(url).text\n",
      "    dom = web.Element(html_text)\n",
      "    all_urls = [x.href for x in dom.by_tag('a')]\n",
      "    \n",
      "    #Throw away URLs that are not block URLS\n",
      "    block_urls = []\n",
      "    for url in all_urls:\n",
      "        if re.search(\"block\",url) != None:\n",
      "            block_urls = block_urls + [url]\n",
      "    \n",
      "    #Create DataFrame\n",
      "    workdelay_df = pd.DataFrame()\n",
      "    for block in block_urls:\n",
      "        block_url = url_start + block\n",
      "        workdelay_df = workdelay_df.append(workdelay_table_extract(block_url))\n",
      "    workdelay_df['year'] = year\n",
      "    return workdelay_df "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**5. Get the data and export it to Excel.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Get data - takes some time to run (~5 min)\n",
      "workdelay_master = pd.DataFrame()\n",
      "for year in year_list:\n",
      "    for dist in district_list:\n",
      "        workdelay_master = workdelay_master.append(workdelay_district_tables(url_head, state_id1, state_id2, dist[0], dist[1], year))\n",
      "\n",
      "#Order columns\n",
      "col_list = ['year','state','district','block','gp','delay_1to30','delay_30to60','delay_60to90','delay_more90','delay_total']\n",
      "workdelay_master = workdelay_master[col_list]\n",
      "\n",
      "#Export to Excel (to save time using below)\n",
      "workdelay_master.to_excel(\"Work Delays Data.xls\",\"Sheet1\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}